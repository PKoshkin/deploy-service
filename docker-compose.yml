services:
  meta-llama-Llama-3.2-1B-Instruct:
    command:
    - --model
    - meta-llama/Llama-3.2-1B-Instruct
    - --disable-log-requests
    - --trust-remote-code
    - --gpu-memory-utilization
    - '0.32'
    container_name: meta-llama-Llama-3.2-1B-Instruct
    deploy:
      resources:
        reservations:
          devices:
            - capabilities:
              - gpu
              device_ids:
              - '0'
              driver: nvidia
    environment:
    - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
    image: vllm/vllm-openai:latest
    ports:
    - 8100:8000
    restart: always
    volumes:
    - ${HUGGINGFACECACHE}:/root/.cache/huggingface
version: '3.7'
